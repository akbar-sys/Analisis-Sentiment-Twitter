{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8102dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "864bf9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negatif    112\n",
       "Positif    119\n",
       "Netral     159\n",
       "Name: sentimen, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"New Scrap.csv\", usecols=[\"tweet\", \"Sentimen\"])\n",
    "df.columns = [\"tweet\", \"sentimen\"]\n",
    "df['sentimen'].value_counts(ascending=True)\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6cb27e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [jadi, pengen, urging, kalian, aja, yang, seha...\n",
       "1    [erick, thohir, mengatakan, indonesia, memilik...\n",
       "2    [pemerintah, terus, berupaya, keras, untuk, me...\n",
       "3    [alamdulillah, pokoknya, jgn, pernah, nyopot, ...\n",
       "4                    [lanjutkan, vaksin, merah, putih]\n",
       "5    [pemerintahan, jokowi, kembali, menerima, kiri...\n",
       "6    [kalau, kalian, di, pekanbaru, dan, eligible, ...\n",
       "7    [enggak, usah, degan, vaksin, aman, kok, ku, j...\n",
       "8    [erick, thohir, terima, 8, juta, bulk, vaksin,...\n",
       "9    [amankan, kebutuhan, vaksin, pemerintah, kemba...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_rekonizing(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(word_rekonizing)\n",
    "datatweet = df['tweet']\n",
    "datatweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d12eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisasi\n",
    "norm = pd.read_excel(\"baru normalisasi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6d47750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [jadi, pengen, urging, kalian, saja, yang, seh...\n",
       "1    [erick, thohir, mengatakan, indonesia, memilik...\n",
       "2    [pemerintah, terus, berupaya, keras, untuk, me...\n",
       "3    [alamdulillah, pokoknya, jangan, pernah, nyopo...\n",
       "4                    [lanjutkan, vaksin, merah, putih]\n",
       "5    [pemerintahan, jokowi, kembali, menerima, kiri...\n",
       "6    [kalau, kalian, di, pekanbaru, dan, eligible, ...\n",
       "7    [enggak, perlu, degan, vaksin, aman, kok, aku,...\n",
       "8    [erick, thohir, terima, 8, juta, bulk, vaksin,...\n",
       "9    [amankan, kebutuhan, vaksin, pemerintah, kemba...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_normalisasi = {}\n",
    "\n",
    "for index, row in norm.iterrows():\n",
    "    if row[0] not in dict_normalisasi:\n",
    "        dict_normalisasi[row[0]]= row[1]\n",
    "\n",
    "def normalisasi_term(data):\n",
    "    return [dict_normalisasi[term] if term in dict_normalisasi else term for term in data]\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(normalisasi_term)\n",
    "df['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2bd77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68805cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
    "                      'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', \n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah', 'kali', 'wkwkwk', 'udh',\n",
    "                       'oke', 'deh', 'tu', 'jg', 'lo', 'blm', 'yaa',\n",
    "                       'pas', 'gitu', 'dapet', 'anjir', 'abg', 'eh', 'tetep',' ya'])\n",
    "#convert list to dictionary\n",
    "list_stopwords = set(list_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91687a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [pengen, urging, sehat, divaksin, please, go, ...\n",
      "1    [erick, thohir, indonesia, memiliki, 759, juta...\n",
      "2    [pemerintah, berupaya, keras, menghadirkan, va...\n",
      "3    [alamdulillah, pokoknya, nyopot, masker, gusss...\n",
      "4                    [lanjutkan, vaksin, merah, putih]\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(stopwords_removal) \n",
    "\n",
    "\n",
    "print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3470806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensi df : (390, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"dimensi df :\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bfddaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cool\n",
      "390 195\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>[egosi, ajalah, intinya, pakai, masker, pakai,...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>[vaksin, pis, eligible, kriteria, divaksin]</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[2x, vaksin, jangka, 3bulanan, vaksin, ipb, eh...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>[goblog, dipiara, anak, tetangga, divaksin, ca...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>[alhamdulillah, siang, tambahan, 8, juta, vaks...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lanjutkan, vaksin, merah, putih]</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[perkucingan, gede, vaksin, anak, 3]</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[amankan, kebutuhan, vaksin, pemerintah, datan...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[erick, thohir, terima, 8, juta, bulk, vaksin,...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>[politikus, partai, gerindra, fadli, zon, terp...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet sentimen\n",
       "144  [egosi, ajalah, intinya, pakai, masker, pakai,...   Netral\n",
       "201        [vaksin, pis, eligible, kriteria, divaksin]   Netral\n",
       "124  [2x, vaksin, jangka, 3bulanan, vaksin, ipb, eh...   Netral\n",
       "288  [goblog, dipiara, anak, tetangga, divaksin, ca...  Negatif\n",
       "243  [alhamdulillah, siang, tambahan, 8, juta, vaks...   Netral\n",
       "..                                                 ...      ...\n",
       "4                    [lanjutkan, vaksin, merah, putih]  Positif\n",
       "188               [perkucingan, gede, vaksin, anak, 3]   Netral\n",
       "9    [amankan, kebutuhan, vaksin, pemerintah, datan...  Positif\n",
       "8    [erick, thohir, terima, 8, juta, bulk, vaksin,...  Positif\n",
       "323  [politikus, partai, gerindra, fadli, zon, terp...  Negatif\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr = df.sample(frac=.50)\n",
    "if (0.50*(len(df))== len(dfr)):\n",
    "    print( \"Cool\")\n",
    "    print(len(df), len(dfr))\n",
    "#display\n",
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1f32032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pengen, urging, sehat, divaksin, please, go, ...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[erick, thohir, indonesia, memiliki, 759, juta...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[alamdulillah, pokoknya, nyopot, masker, gusss...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[pemerintahan, jokowi, menerima, kiriman, vaks...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[degan, vaksin, aman, suntik, glombang, bulang...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentimen\n",
       "0  [pengen, urging, sehat, divaksin, please, go, ...  Positif\n",
       "1  [erick, thohir, indonesia, memiliki, 759, juta...  Positif\n",
       "3  [alamdulillah, pokoknya, nyopot, masker, gusss...  Positif\n",
       "5  [pemerintahan, jokowi, menerima, kiriman, vaks...  Positif\n",
       "7  [degan, vaksin, aman, suntik, glombang, bulang...  Positif"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa= df.drop(dfr.index)\n",
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93da717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [pengen, urging, sehat, divaksin, please, go, ...\n",
      "1      [erick, thohir, indonesia, memiliki, 759, juta...\n",
      "2      [pemerintah, berupaya, keras, menghadirkan, va...\n",
      "3      [alamdulillah, pokoknya, nyopot, masker, gusss...\n",
      "4                      [lanjutkan, vaksin, merah, putih]\n",
      "                             ...                        \n",
      "385                               [vaksin, pengangguran]\n",
      "386    [iya, lambat, vaksin, lokal, keburu, bubaran, ...\n",
      "387    [masyarakat, takut, vaksin, walikota, kendari,...\n",
      "388    [vaksinnya, ngga, vaksin, prewe, kampus, aing,...\n",
      "389    [vaksin, prosedurnya, susah, males, klu, klu, ...\n",
      "Name: tweet, Length: 390, dtype: object\n",
      "0      Positif\n",
      "1      Positif\n",
      "2      Positif\n",
      "3      Positif\n",
      "4      Positif\n",
      "        ...   \n",
      "385    Negatif\n",
      "386    Negatif\n",
      "387    Negatif\n",
      "388    Negatif\n",
      "389    Negatif\n",
      "Name: sentimen, Length: 390, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x=df[\"tweet\"]\n",
    "y=df[\"sentimen\"]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06764767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'pengen': 0.043478260869565216, 'urging': 0.0...\n",
       "1      {'erick': 0.043478260869565216, 'thohir': 0.04...\n",
       "2      {'pemerintah': 0.03571428571428571, 'berupaya'...\n",
       "3      {'alamdulillah': 0.09090909090909091, 'pokokny...\n",
       "4      {'lanjutkan': 0.25, 'vaksin': 0.25, 'merah': 0...\n",
       "                             ...                        \n",
       "385                 {'vaksin': 0.5, 'pengangguran': 0.5}\n",
       "386    {'iya': 0.14285714285714285, 'lambat': 0.14285...\n",
       "387    {'masyarakat': 0.14285714285714285, 'takut': 0...\n",
       "388    {'vaksinnya': 0.125, 'ngga': 0.125, 'vaksin': ...\n",
       "389    {'vaksin': 0.06666666666666667, 'prosedurnya':...\n",
       "Name: TF_dict, Length: 390, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf \n",
    "def calc_TF(document):\n",
    "    # Counts the number of times the word appears in review\n",
    "    TF_dict = {}\n",
    "    for term in document:\n",
    "        if term in TF_dict:\n",
    "            TF_dict[term] += 1\n",
    "        else:\n",
    "            TF_dict[term] = 1\n",
    "    # Computes tf for each word\n",
    "    for term in TF_dict:\n",
    "        TF_dict[term] = TF_dict[term] / len(document)\n",
    "    return TF_dict\n",
    "\n",
    "df['TF_dict'] = df[\"tweet\"].apply(calc_TF)\n",
    "df[\"TF_dict\"]\n",
    "#df[\"TF_dict\"] = df['tweet'].apply(calc_TF)\n",
    "#df[\"TF_dict\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d532f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idf\n",
    "def calc_DF(tfDict):\n",
    "    count_DF = {}\n",
    "    # Run through each document's tf dictionary and increment countDict's (term, doc) pair\n",
    "    for document in tfDict:\n",
    "        for term in document:\n",
    "            if term in count_DF:\n",
    "                count_DF[term] += 1\n",
    "            else:\n",
    "                count_DF[term] = 1\n",
    "    return count_DF\n",
    "\n",
    "\n",
    "DF = calc_DF(df[\"TF_dict\"])\n",
    "#DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d088a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_document = len(df)\n",
    "\n",
    "def calc_IDF(__n_document, __DF):\n",
    "    IDF_Dict = {}\n",
    "    for term in __DF:\n",
    "        IDF_Dict[term] = np.log(__n_document / (__DF[term] + 1))\n",
    "    return IDF_Dict\n",
    "  \n",
    "#Stores the idf dictionary\n",
    "IDF = calc_IDF(n_document, DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cecf9198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'pengen': 0.21163193262850358, 'urging': 0.22...\n",
       "1    {'erick': 0.16898718249755895, 'thohir': 0.174...\n",
       "2    {'pemerintah': 0.10109473297123366, 'berupaya'...\n",
       "3    {'alamdulillah': 0.4793635962330679, 'pokoknya...\n",
       "4    {'lanjutkan': 1.3182498896409367, 'vaksin': 0....\n",
       "Name: TF-IDF_dict, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calc TF-IDF\n",
    "def calc_TF_IDF(TF):\n",
    "    TF_IDF_Dict = {}\n",
    "    #For each word in the review, we multiply its tf and its idf.\n",
    "    for key in TF:\n",
    "        TF_IDF_Dict[key] = TF[key] * IDF[key]\n",
    "    return TF_IDF_Dict\n",
    "\n",
    "#Stores the TF-IDF Series\n",
    "df[\"TF-IDF_dict\"] = df[\"TF_dict\"].apply(calc_TF_IDF)\n",
    "df[\"TF-IDF_dict\"].head()\n",
    "#hasil_tfidf = dftrain[\"TF-IDF_dict\"]\n",
    "#hasil_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fe0d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "0      [0.0007874673888280914, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "1      [0.0007874673888280914, 0.1980232421747614, 0....\n",
      "2      [0.001293696424503293, 0.08133097446463414, 0....\n",
      "3      [0.0016465227220951004, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "4      [0.004527937485761526, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "                             ...                        \n",
      "114    [0.006037249981015368, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "115    [0.004527937485761526, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "116    [0.0, 0.0, 0.0, 0.0, 0.0, 0.4513417001837017, ...\n",
      "117    [0.0006468482122516465, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "118    [0.0010653970554733003, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "Name: TF_IDF_Vec, Length: 119, dtype: object\n",
      "\n",
      "matrix size :  119\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(calc_DF(df[\"TF_dict\"][df[\"sentimen\"] == \"Positif\"]).items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "df[\"TF_IDF_Vec\"] = df[\"TF-IDF_dict\"][df['sentimen'] == 'Positif'].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Positif'])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Positif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed4a1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juta</td>\n",
       "      <td>6.635892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dosis</td>\n",
       "      <td>5.605287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>4.552397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vaksinasi</td>\n",
       "      <td>3.699357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sinovac</td>\n",
       "      <td>3.676219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baku</td>\n",
       "      <td>3.395126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bahan</td>\n",
       "      <td>3.339360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>3.220683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid19</td>\n",
       "      <td>3.196804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.309589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term      rank\n",
       "1        juta  6.635892\n",
       "3       dosis  5.605287\n",
       "2   indonesia  4.552397\n",
       "5   vaksinasi  3.699357\n",
       "8     sinovac  3.676219\n",
       "7        baku  3.395126\n",
       "6       bahan  3.339360\n",
       "9  pemerintah  3.220683\n",
       "4     covid19  3.196804\n",
       "0      vaksin  0.309589"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to List\n",
    "TF_IDF_Vec_List = np.array(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Positif'].to_list())\n",
    "\n",
    "# Sum element vector in axis=0 \n",
    "sums = TF_IDF_Vec_List.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(unique_term):\n",
    "    data.append((term, sums[col]))\n",
    "    \n",
    "rankingPos = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "rankingPos.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf3c798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "278    [0.0027864230681609392, 0.0, 0.0, 0.0, 0.23243...\n",
      "279    [0.0006037249981015368, 0.08901032910397877, 0...\n",
      "280    [0.0007874673888280914, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "281    [0.006037249981015368, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "282    [0.0027864230681609392, 0.0, 0.0, 0.0, 0.23243...\n",
      "                             ...                        \n",
      "385    [0.009055874971523051, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "386    [0.002587392849006586, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "387    [0.002587392849006586, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "388    [0.002263968742880763, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "389    [0.0012074499962030736, 0.0, 0.0, 0.1980276310...\n",
      "Name: TF_IDF_Vec, Length: 112, dtype: object\n",
      "\n",
      "matrix size :  112\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(calc_DF(df[\"TF_dict\"][df[\"sentimen\"] == \"Negatif\"]).items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "df[\"TF_IDF_Vec\"] = df[\"TF-IDF_dict\"][df['sentimen'] == 'Negatif'].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Negatif'])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Negatif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d74a1cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mati</td>\n",
       "      <td>3.685168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selesai</td>\n",
       "      <td>3.588159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orang</td>\n",
       "      <td>3.442410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>divaksin</td>\n",
       "      <td>2.948010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid19</td>\n",
       "      <td>2.741055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>takut</td>\n",
       "      <td>2.473329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.924562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>covid</td>\n",
       "      <td>1.738674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>0.919606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.308759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term      rank\n",
       "6       mati  3.685168\n",
       "3    selesai  3.588159\n",
       "1      orang  3.442410\n",
       "4   divaksin  2.948010\n",
       "2    covid19  2.741055\n",
       "9      takut  2.473329\n",
       "5          2  1.924562\n",
       "8      covid  1.738674\n",
       "7  indonesia  0.919606\n",
       "0     vaksin  0.308759"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to List\n",
    "TF_IDF_Vec_List = np.array(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Negatif'].to_list())\n",
    "\n",
    "# Sum element vector in axis=0 \n",
    "sums = TF_IDF_Vec_List.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(unique_term):\n",
    "    data.append((term, sums[col]))\n",
    "    \n",
    "rankingNeg = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "rankingNeg.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abe60304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "119    [0.0017249285660043906, 0.20566516660508305, 0...\n",
      "120    [0.000754656247626921, 0.0, 0.0, 0.0, 0.130538...\n",
      "121    [0.0006245431014843484, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "122    [0.001509312495253842, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "123    [0.0020699142792052687, 0.061699549981524916, ...\n",
      "                             ...                        \n",
      "273    [0.002414899992406147, 0.0, 0.1646426118438141...\n",
      "274    [0.002263968742880763, 0.2699355311691715, 0.0...\n",
      "275    [0.0020124166603384557, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "276    [0.004527937485761526, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "277    [0.0012074499962030736, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "Name: TF_IDF_Vec, Length: 159, dtype: object\n",
      "\n",
      "matrix size :  159\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(calc_DF(df[\"TF_dict\"][df[\"sentimen\"] == \"Netral\"]).items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "df[\"TF_IDF_Vec\"] = df[\"TF-IDF_dict\"][df['sentimen'] == 'Netral'].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Netral'])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Netral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aea37abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sinovac</td>\n",
       "      <td>4.240616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ya</td>\n",
       "      <td>3.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>suntik</td>\n",
       "      <td>3.785142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>3.562652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juta</td>\n",
       "      <td>2.874958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banget</td>\n",
       "      <td>2.748011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dosis</td>\n",
       "      <td>2.557788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>covid</td>\n",
       "      <td>2.210483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covid19</td>\n",
       "      <td>1.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.425607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term      rank\n",
       "2    sinovac  4.240616\n",
       "6        ya   3.912109\n",
       "8     suntik  3.785142\n",
       "1  indonesia  3.562652\n",
       "3       juta  2.874958\n",
       "4     banget  2.748011\n",
       "7      dosis  2.557788\n",
       "5      covid  2.210483\n",
       "9    covid19  1.796200\n",
       "0     vaksin  0.425607"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to List\n",
    "TF_IDF_Vec_List = np.array(df[\"TF_IDF_Vec\"][df['sentimen'] == 'Netral'].to_list())\n",
    "\n",
    "# Sum element vector in axis=0 \n",
    "sums = TF_IDF_Vec_List.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(unique_term):\n",
    "    data.append((term, sums[col]))\n",
    "    \n",
    "rankingNet = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "rankingNet.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8970cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.309589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juta</td>\n",
       "      <td>6.635892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>4.552397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dosis</td>\n",
       "      <td>5.605287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid19</td>\n",
       "      <td>3.196804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vaksinasi</td>\n",
       "      <td>3.699357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bahan</td>\n",
       "      <td>3.339360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baku</td>\n",
       "      <td>3.395126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sinovac</td>\n",
       "      <td>3.676219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>3.220683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.308759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>orang</td>\n",
       "      <td>3.442410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>covid19</td>\n",
       "      <td>2.741055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>selesai</td>\n",
       "      <td>3.588159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>divaksin</td>\n",
       "      <td>2.948010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1.924562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mati</td>\n",
       "      <td>3.685168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>0.919606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>covid</td>\n",
       "      <td>1.738674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>takut</td>\n",
       "      <td>2.473329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.425607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>3.562652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sinovac</td>\n",
       "      <td>4.240616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>juta</td>\n",
       "      <td>2.874958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>banget</td>\n",
       "      <td>2.748011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>covid</td>\n",
       "      <td>2.210483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ya</td>\n",
       "      <td>3.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dosis</td>\n",
       "      <td>2.557788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>suntik</td>\n",
       "      <td>3.785142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>covid19</td>\n",
       "      <td>1.796200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term   ranking\n",
       "0       vaksin  0.309589\n",
       "1         juta  6.635892\n",
       "2    indonesia  4.552397\n",
       "3        dosis  5.605287\n",
       "4      covid19  3.196804\n",
       "5    vaksinasi  3.699357\n",
       "6        bahan  3.339360\n",
       "7         baku  3.395126\n",
       "8      sinovac  3.676219\n",
       "9   pemerintah  3.220683\n",
       "10      vaksin  0.308759\n",
       "11       orang  3.442410\n",
       "12     covid19  2.741055\n",
       "13     selesai  3.588159\n",
       "14    divaksin  2.948010\n",
       "15           2  1.924562\n",
       "16        mati  3.685168\n",
       "17   indonesia  0.919606\n",
       "18       covid  1.738674\n",
       "19       takut  2.473329\n",
       "20      vaksin  0.425607\n",
       "21   indonesia  3.562652\n",
       "22     sinovac  4.240616\n",
       "23        juta  2.874958\n",
       "24      banget  2.748011\n",
       "25       covid  2.210483\n",
       "26         ya   3.912109\n",
       "27       dosis  2.557788\n",
       "28      suntik  3.785142\n",
       "29     covid19  1.796200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = pd.concat([rankingPos,rankingNeg,rankingNet],axis=0,ignore_index=True)\n",
    "feature.columns = [\"term\", \"ranking\"]\n",
    "#feature.columns = [\"termPositif\", \"rankingPositif\", \"termNegatif\", \"rankingNegatif\", \"termNetral\", \"rankingNetral\",]\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61ae31b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaksin</td>\n",
       "      <td>0.309589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juta</td>\n",
       "      <td>6.635892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>4.552397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dosis</td>\n",
       "      <td>5.605287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid19</td>\n",
       "      <td>3.196804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vaksinasi</td>\n",
       "      <td>3.699357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bahan</td>\n",
       "      <td>3.339360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baku</td>\n",
       "      <td>3.395126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sinovac</td>\n",
       "      <td>3.676219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>3.220683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>orang</td>\n",
       "      <td>3.442410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>selesai</td>\n",
       "      <td>3.588159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>divaksin</td>\n",
       "      <td>2.948010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1.924562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mati</td>\n",
       "      <td>3.685168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>covid</td>\n",
       "      <td>1.738674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>takut</td>\n",
       "      <td>2.473329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>banget</td>\n",
       "      <td>2.748011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ya</td>\n",
       "      <td>3.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>suntik</td>\n",
       "      <td>3.785142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term   ranking\n",
       "0       vaksin  0.309589\n",
       "1         juta  6.635892\n",
       "2    indonesia  4.552397\n",
       "3        dosis  5.605287\n",
       "4      covid19  3.196804\n",
       "5    vaksinasi  3.699357\n",
       "6        bahan  3.339360\n",
       "7         baku  3.395126\n",
       "8      sinovac  3.676219\n",
       "9   pemerintah  3.220683\n",
       "11       orang  3.442410\n",
       "13     selesai  3.588159\n",
       "14    divaksin  2.948010\n",
       "15           2  1.924562\n",
       "16        mati  3.685168\n",
       "18       covid  1.738674\n",
       "19       takut  2.473329\n",
       "24      banget  2.748011\n",
       "26         ya   3.912109\n",
       "28      suntik  3.785142"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitur = feature.drop_duplicates(subset='term', keep=\"first\")\n",
    "fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c97da0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vaksin', 'juta', 'indonesia', 'dosis', 'covid19', 'vaksinasi', 'bahan', 'baku', 'sinovac', 'pemerintah', 'orang', 'selesai', 'divaksin', '2', 'mati', 'covid', 'takut', 'banget', 'ya ', 'suntik']\n"
     ]
    }
   ],
   "source": [
    "keyword_list = fitur[\"term\"].values.tolist()\n",
    "print (keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea50568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaksin</th>\n",
       "      <th>juta</th>\n",
       "      <th>indonesia</th>\n",
       "      <th>dosis</th>\n",
       "      <th>covid19</th>\n",
       "      <th>vaksinasi</th>\n",
       "      <th>bahan</th>\n",
       "      <th>baku</th>\n",
       "      <th>sinovac</th>\n",
       "      <th>pemerintah</th>\n",
       "      <th>orang</th>\n",
       "      <th>selesai</th>\n",
       "      <th>divaksin</th>\n",
       "      <th>2</th>\n",
       "      <th>mati</th>\n",
       "      <th>covid</th>\n",
       "      <th>takut</th>\n",
       "      <th>banget</th>\n",
       "      <th>ya</th>\n",
       "      <th>suntik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.281672</td>\n",
       "      <td>0.103593</td>\n",
       "      <td>0.099012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.081331</td>\n",
       "      <td>0.077124</td>\n",
       "      <td>0.085094</td>\n",
       "      <td>0.081331</td>\n",
       "      <td>0.096716</td>\n",
       "      <td>0.104344</td>\n",
       "      <td>0.106086</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>0.101095</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.198028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vaksin      juta  indonesia     dosis   covid19  vaksinasi     bahan  \\\n",
       "0    0.000787  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "1    0.000787  0.198023   0.281672  0.103593  0.099012   0.000000  0.000000   \n",
       "2    0.001294  0.081331   0.077124  0.085094  0.081331   0.096716  0.104344   \n",
       "3    0.001647  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "4    0.004528  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "..        ...       ...        ...       ...       ...        ...       ...   \n",
       "385  0.009056  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "386  0.002587  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "387  0.002587  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "388  0.002264  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "389  0.001207  0.000000   0.143966  0.000000  0.000000   0.180537  0.000000   \n",
       "\n",
       "         baku   sinovac  pemerintah   orang   selesai  divaksin         2  \\\n",
       "0    0.000000  0.000000    0.000000  0.0000  0.000000  0.131379  0.000000   \n",
       "1    0.000000  0.000000    0.000000  0.1161  0.000000  0.000000  0.127027   \n",
       "2    0.106086  0.088201    0.101095  0.0000  0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "4    0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "..        ...       ...         ...     ...       ...       ...       ...   \n",
       "385  0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "386  0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "387  0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "388  0.000000  0.000000    0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "389  0.000000  0.000000    0.000000  0.0000  0.198028  0.000000  0.000000   \n",
       "\n",
       "     mati  covid     takut    banget       ya   suntik  \n",
       "0     0.0    0.0  0.000000  0.272429  0.000000     0.0  \n",
       "1     0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "2     0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "3     0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "4     0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "..    ...    ...       ...       ...       ...     ...  \n",
       "385   0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "386   0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "387   0.0    0.0  0.475298  0.000000  0.000000     0.0  \n",
       "388   0.0    0.0  0.000000  0.000000  0.000000     0.0  \n",
       "389   0.0    0.0  0.000000  0.000000  0.212904     0.0  \n",
       "\n",
       "[390 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dseries = df[\"TF-IDF_dict\"].apply(pd.Series)\n",
    "new_dseries = dseries.fillna(0)\n",
    "dtfidf = pd.DataFrame(new_dseries, columns=keyword_list)\n",
    "dtfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cbee93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vaksin  juta  indonesia  dosis   covid19  vaksinasi  bahan  baku  \\\n",
      "106  0.012074   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "67   0.003196   0.0        0.0    0.0  0.133957        0.0    0.0   0.0   \n",
      "77   0.003622   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "271  0.003019   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "356  0.003293   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "..        ...   ...        ...    ...       ...        ...    ...   ...   \n",
      "333  0.002860   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "165  0.000755   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "147  0.002587   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "387  0.002587   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "358  0.001811   0.0        0.0    0.0  0.000000        0.0    0.0   0.0   \n",
      "\n",
      "     sinovac  pemerintah     orang   selesai  divaksin    2  mati     covid  \\\n",
      "106      0.0    0.000000  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "67       0.0    0.166509  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "77       0.0    0.000000  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "271      0.0    0.000000  0.000000  0.495069       0.0  0.0   0.0  0.000000   \n",
      "356      0.0    0.000000  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "..       ...         ...       ...       ...       ...  ...   ...       ...   \n",
      "333      0.0    0.000000  0.140543  0.156338       0.0  0.0   0.0  0.000000   \n",
      "165      0.0    0.000000  0.111263  0.000000       0.0  0.0   0.0  0.119796   \n",
      "147      0.0    0.000000  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "387      0.0    0.000000  0.000000  0.000000       0.0  0.0   0.0  0.000000   \n",
      "358      0.0    0.000000  0.267031  0.000000       0.0  0.0   0.0  0.000000   \n",
      "\n",
      "        takut  banget       ya   suntik  \n",
      "106  0.000000     0.0  0.000000     0.0  \n",
      "67   0.000000     0.0  0.000000     0.0  \n",
      "77   0.000000     0.0  0.000000     0.0  \n",
      "271  0.000000     0.0  0.532260     0.0  \n",
      "356  0.000000     0.0  0.000000     0.0  \n",
      "..        ...     ...       ...     ...  \n",
      "333  0.000000     0.0  0.000000     0.0  \n",
      "165  0.138629     0.0  0.133065     0.0  \n",
      "147  0.000000     0.0  0.000000     0.0  \n",
      "387  0.475298     0.0  0.000000     0.0  \n",
      "358  0.000000     0.0  0.000000     0.0  \n",
      "\n",
      "[312 rows x 20 columns]\n",
      "(78,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dtfidf, y, test_size = 0.2)\n",
    "print(x_train)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49e58ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "prediksi = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "732ef5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e242a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " akurasi 0.47435897435897434\n",
      "\n",
      " ak               precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.75      0.12      0.21        25\n",
      "      Netral       0.43      0.94      0.59        31\n",
      "     Positif       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.47        78\n",
      "   macro avg       0.67      0.43      0.38        78\n",
      "weighted avg       0.64      0.47      0.40        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n akurasi', metrics.accuracy_score(y_test,prediksi))\n",
    "print('\\n ak', metrics.classification_report(y_test,prediksi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "343e3982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentimen'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(prediksi, columns=['sentimen'])\n",
    "df1.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea58b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
